{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Create TensorFlow model </h1>\n",
    "\n",
    "This notebook illustrates:\n",
    "<ol>\n",
    "<li> Creating a model using the high-level Estimator API \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change these to try this notebook out\n",
    "BUCKET = 'cloud-training-demos-ml'\n",
    "PROJECT = 'cloud-training-demos'\n",
    "REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "if ! gsutil ls | grep -q gs://${BUCKET}/; then\n",
    "  gsutil mb -l ${REGION} gs://${BUCKET}\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Create TensorFlow model using TensorFlow's Estimator API </h2>\n",
    "<p>\n",
    "First, write an input_fn to read the data.\n",
    "<p>\n",
    "\n",
    "## Lab Task 1\n",
    "Verify that the headers match your CSV output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval.csv  train.csv\r\n"
     ]
    }
   ],
   "source": [
    "# csv 파일이 있나 확인하자.\n",
    "!ls *.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine CSV, label, and key columns\n",
    "CSV_COLUMNS = 'weight_pounds,is_male,mother_age,plurality,gestation_weeks,key'.split(',')\n",
    "LABEL_COLUMN = 'weight_pounds'\n",
    "KEY_COLUMN = 'key'\n",
    "\n",
    "# Set default values for each CSV column\n",
    "DEFAULTS = [[0.0], ['null'], [0.0], ['null'], [0.0], ['nokey']]\n",
    "TRAIN_STEPS = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Task 2\n",
    "\n",
    "Fill out the details of the input function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an input function reading a file using the Dataset API\n",
    "# Then provide the results to the Estimator API\n",
    "def read_dataset(filename_pattern, mode, batch_size = 512):\n",
    "    def _input_fn():\n",
    "        def decode_csv(line_of_text):\n",
    "            # TODO #1: Use tf.decode_csv to parse the provided line\n",
    "            # TODO #2: Make a Python dict.  The keys are the column names, the values are from the parsed data\n",
    "            # TODO #3: Return a tuple of features, label where features is a Python dict and label a float\n",
    "            data = tf.decode_csv(line_of_text, record_defaults=DEFAULTS)\n",
    "            features = dict(zip(CSV_COLUMNS, data))\n",
    "            label = features.pop(LABEL_COLUMN)\n",
    "            return features, label\n",
    "    \n",
    "    # TODO #4: Use tf.gfile.Glob to create list of files that match pattern\n",
    "    file_list = tf.gfile.Glob(filename_pattern)\n",
    "\n",
    "    # Create dataset from file list\n",
    "    dataset = (tf.data.TextLineDataset(file_list)  # Read text file\n",
    "                 .map(decode_csv))  # Transform each elem by applying decode_csv fn\n",
    "    \n",
    "    # TODO #5: In training mode, shuffle the dataset and repeat indefinitely\n",
    "    #                (Look at the API for tf.data.dataset shuffle)\n",
    "    #          The mode input variable will be tf.estimator.ModeKeys.TRAIN if in training mode\n",
    "    #          Tell the dataset to provide data in batches of batch_size \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        num_epochs = None # 무기한으로(indefinitely)\n",
    "      \n",
    "      # The Dataset.shuffle() transformation randomly shuffles the input dataset\n",
    "        dataset = dataset.shuffle(buffer_size=10*batch_size)\n",
    "    else:\n",
    "        num_epochs = 1 # end-of-input after this\n",
    "      \n",
    "    dataset = dataset.repeat(num_epochs).batch(batch_size)      \n",
    "    # This will now return batches of features, label\n",
    "    return dataset\n",
    "  return _input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Task 3\n",
    "\n",
    "Use the TensorFlow feature column API to define appropriate feature columns for your raw features that come from the CSV.\n",
    "\n",
    "<b> Bonus: </b> Separate your columns into wide columns (categorical, discrete, etc.) and deep columns (numeric, embedding, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns\n",
    "def get_categorical(column_name, categories):\n",
    "  # in-memory vocabulary mapping to an integer ID\n",
    "  return tf.feature_column.indicator_column(\n",
    "                tf.feature_column.categorical_column_with_vocabulary_list(column_name, categories))\n",
    "  \n",
    "def get_cols():\n",
    "  # Define column types\n",
    "  return [\\\n",
    "         get_categorical('is_male', ['True', 'False', 'Unknown']),\n",
    "         tf.feature_column.numeric_column('mother_age'),\n",
    "         get_categorical('plurality', ['Single(1)', 'Twins(2)', 'Triplets(3)',\n",
    "                       'Quadruplets(4)', 'Quintuplets(5)','Multiple(2+)']),\n",
    "         tf.feature_column.numeric_column('gestation_weeks')\n",
    "         ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Task 4\n",
    "\n",
    "To predict with the TensorFlow model, we also need a serving input function (we'll use this in a later lab). We will want all the inputs from our user.\n",
    "\n",
    "Verify and change the column names and types here as appropriate. These should match your CSV_COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create serving input function to be able to serve predictions later using provided inputs\n",
    "def serving_input_fn():\n",
    "    feature_placeholders = {\n",
    "        'is_male': tf.placeholder(tf.string, [None]),\n",
    "        'mother_age': tf.placeholder(tf.float32, [None]),\n",
    "        'plurality': tf.placeholder(tf.string, [None]),\n",
    "        'gestation_weeks': tf.placeholder(tf.float32, [None])\n",
    "    }\n",
    "    features = {\n",
    "        key: tf.expand_dims(tensor, -1)\n",
    "        for key, tensor in feature_placeholders.items()\n",
    "    }\n",
    "    return tf.estimator.export.ServingInputReceiver(features, feature_placeholders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Task 5\n",
    "\n",
    "Complete the TODOs in this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create estimator to train and evaluate\n",
    "def train_and_evaluate(output_dir):\n",
    "    EVAL_INTERVAL = 300\n",
    "    run_config = tf.estimator.RunConfig(save_checkpoints_secs = EVAL_INTERVAL,\n",
    "                                      keep_checkpoint_max = 3)\n",
    "    # TODO #1: Create your estimator\n",
    "    estimator = tf.estimator.DNNRegressor(\n",
    "                      hidden_units = [128, 64, 32],\n",
    "                      feature_columns = get_cols(),\n",
    "                      model_dir = output_dir, # directory to save model parameters, graphs..\n",
    "                      optimizer = 'Adam')\n",
    "\n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "                       # TODO #2: Call read_dataset passing in the training CSV file and the appropriate mode\n",
    "                       input_fn = read_dataset('train.csv', mode = tf.estimator.ModeKeys.TRAIN),\n",
    "                       max_steps = TRAIN_STEPS)\n",
    "    exporter = tf.estimator.LatestExporter('exporter', serving_input_fn)\n",
    "    eval_spec = tf.estimator.EvalSpec(\n",
    "                       # TODO #3: Call read_dataset passing in the evaluation CSV file and the appropriate mode\n",
    "                       input_fn = read_dataset('eval.csv', mode = tf.estimator.ModeKeys.EVAL),\n",
    "                       steps = None,\n",
    "                       start_delay_secs = 60, # start evaluating after N seconds\n",
    "                       throttle_secs = EVAL_INTERVAL,  # evaluate every N seconds\n",
    "                       exporters = exporter)\n",
    "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_session_config': None, '_tf_random_seed': None, '_num_worker_replicas': 1, '_log_step_count_steps': 100, '_service': None, '_global_id_in_cluster': 0, '_keep_checkpoint_every_n_hours': 10000, '_master': '', '_evaluation_master': '', '_keep_checkpoint_max': 5, '_model_dir': 'babyweight_trained', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f67f73d59e8>, '_save_summary_steps': 100, '_is_chief': True, '_num_ps_replicas': 0, '_train_distribute': None, '_save_checkpoints_steps': None, '_task_type': 'worker', '_task_id': 0, '_save_checkpoints_secs': 600}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 300 secs (eval_spec.throttle_secs) or training is finished.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into babyweight_trained/model.ckpt.\n",
      "INFO:tensorflow:loss = 63696.0, step = 1\n",
      "INFO:tensorflow:global_step/sec: 44.7662\n",
      "INFO:tensorflow:loss = 675.2865, step = 101 (2.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.5206\n",
      "INFO:tensorflow:loss = 740.41174, step = 201 (2.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.0889\n",
      "INFO:tensorflow:loss = 609.69507, step = 301 (2.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.8534\n",
      "INFO:tensorflow:loss = 628.51935, step = 401 (2.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.048\n",
      "INFO:tensorflow:loss = 615.87714, step = 501 (2.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.6524\n",
      "INFO:tensorflow:loss = 587.52466, step = 601 (2.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.8852\n",
      "INFO:tensorflow:loss = 606.4886, step = 701 (2.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.6885\n",
      "INFO:tensorflow:loss = 655.2733, step = 801 (2.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.1542\n",
      "INFO:tensorflow:loss = 591.8298, step = 901 (2.267 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into babyweight_trained/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 616.1889.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-18-12:27:12\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from babyweight_trained/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-18-12:27:12\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 1.1771642, global_step = 1000, loss = 589.3065\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO:tensorflow:'serving_default' : Regression input must be a single string Tensor; got {'plurality': <tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=string>, 'gestation_weeks': <tf.Tensor 'Placeholder_3:0' shape=(?,) dtype=float32>, 'mother_age': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>, 'is_male': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=string>}\n",
      "INFO:tensorflow:'regression' : Regression input must be a single string Tensor; got {'plurality': <tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=string>, 'gestation_weeks': <tf.Tensor 'Placeholder_3:0' shape=(?,) dtype=float32>, 'mother_age': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>, 'is_male': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=string>}\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:Restoring parameters from babyweight_trained/model.ckpt-1000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b\"babyweight_trained/export/exporter/temp-b'1560860833'/saved_model.pb\"\n"
     ]
    }
   ],
   "source": [
    "# Run the model\n",
    "shutil.rmtree('babyweight_trained', ignore_errors = True) # start fresh each time\n",
    "tf.summary.FileWriterCache.clear() # ensure filewriter cache is clear for TensorBoard events file\n",
    "train_and_evaluate('babyweight_trained')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I ran it, the average loss from the output was:\n",
    "<pre>\n",
    "INFO:tensorflow:Saving dict for global step 1000: average_loss = 1.1640576...\n",
    "</pre>\n",
    "The exporter directory contains the final model and the final RMSE (the average_loss) is 1.16."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Monitor and experiment with training </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin TensorBoard from within AI Platform Notebooks, click the + symbol in the top left corner and select the Tensorboard icon to create a new TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>TensorBoard was started successfully with pid 4364. Click <a href=\"/_proxy/53363/\" target=\"_blank\">here</a> to access it.</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4364"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.datalab.ml import TensorBoard\n",
    "TensorBoard().start('./babyweight_trained')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorBoard로 확인한 모델 구조는 다음과 같다.\n",
    "![dnn](dnn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In TensorBoard, look at the learned embeddings. Are they getting clustered? How about the weights for the hidden layers? What if you run this longer? What happens if you change the batchsize?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped TensorBoard with pid 3804\n"
     ]
    }
   ],
   "source": [
    "for pid in TensorBoard.list()['pid']:\n",
    "    TensorBoard().stop(pid)\n",
    "    print('Stopped TensorBoard with pid {}'.format(pid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow with Wide and Deep Model\n",
    "선형회귀 모델과 딥러닝 모델을 함께 사용하는 텐서플로우 모델을 만들어보자.\n",
    "위에서 다른 건 다 똑같고, Task3과 Task5만 다르다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns\n",
    "def get_wide_deep():\n",
    "    is_male, mother_age, plurality, gestation_week = \\\n",
    "    [\\\n",
    "     tf.feature_column.categorical_column_with_vocabulary_list('is_male', ['True', 'False', 'Unknown']),\n",
    "     tf.feature_column.numeric_column('mother_age'),\n",
    "     tf.feature_column.categorical_column_with_vocabulary_list('plurality', \n",
    "                    ['Single(1)', 'Twins(2)', 'Triplets(3)', 'Quadruplets(4)', 'Quintuplets(5)','Multiple(2+)']),\n",
    "     tf.feature_column.numeric_column('gestation_weeks')\n",
    "    ]\n",
    "\n",
    "    # wide모델에 먹일 mother_age, gestation_week의 정수값들은 categorize화하자.\n",
    "    age_buckets = tf.feature_column.bucketized_column(mother_age, boundaries=np.arange(15,45,1).tolist()) # [15, 16, ... ,45]\n",
    "    gestation_buckets = tf.feature_column.bucketized_column(gestation_week, boundaries=np.arange(17,47,1).tolist())\n",
    "\n",
    "    # Sparse columns are wide, have a linear relationship with the input\n",
    "    wide = [is_male, plurality, age_buckets, gestation_buckets]\n",
    "\n",
    "    # Feature cross all the wide columns and embed into a lower dimension\n",
    "    crossed = tf.feature_column.crossed_column(wide, hash_bucket_size=20000)\n",
    "    embed = tf.feature_column.embedding_column(crossed, 3)\n",
    "\n",
    "    # Continuous columns are deep, have a complex relationship with the output\n",
    "    deep = [mother_age, gestation_week, embed]\n",
    "    return wide, deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create estimator to train and evaluate\n",
    "def train_and_evaluate(output_dir):\n",
    "    wide, deep = get_wide_deep()\n",
    "    EVAL_INTERVAL = 300\n",
    "    run_config = tf.estimator.RunConfig(save_checkpoints_secs = EVAL_INTERVAL,\n",
    "                                      keep_checkpoint_max = 3)\n",
    "    estimator = tf.estimator.DNNLinearCombinedRegressor(\n",
    "                       model_dir = output_dir,\n",
    "                       linear_feature_columns = wide,\n",
    "                       dnn_feature_columns = deep,\n",
    "                       dnn_hidden_units = [64, 32],\n",
    "                       config = run_config)\n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "                       input_fn = read_dataset('train.csv', mode = tf.estimator.ModeKeys.TRAIN),\n",
    "                       max_steps = TRAIN_STEPS)\n",
    "    exporter = tf.estimator.LatestExporter('exporter', serving_input_fn)\n",
    "    eval_spec = tf.estimator.EvalSpec(\n",
    "                       input_fn = read_dataset('eval.csv', mode = tf.estimator.ModeKeys.EVAL),\n",
    "                       steps = None,\n",
    "                       start_delay_secs = 60, # start evaluating after N seconds\n",
    "                       throttle_secs = EVAL_INTERVAL,  # evaluate every N seconds\n",
    "                       exporters = exporter)\n",
    "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_session_config': None, '_tf_random_seed': None, '_num_worker_replicas': 1, '_log_step_count_steps': 100, '_service': None, '_global_id_in_cluster': 0, '_keep_checkpoint_every_n_hours': 10000, '_master': '', '_evaluation_master': '', '_keep_checkpoint_max': 3, '_model_dir': 'babyweight_trained', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f67f7f8f6d8>, '_save_summary_steps': 100, '_is_chief': True, '_num_ps_replicas': 0, '_train_distribute': None, '_save_checkpoints_steps': None, '_task_type': 'worker', '_task_id': 0, '_save_checkpoints_secs': 300}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 300 secs (eval_spec.throttle_secs) or training is finished.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into babyweight_trained/model.ckpt.\n",
      "INFO:tensorflow:loss = 16954.316, step = 1\n",
      "INFO:tensorflow:global_step/sec: 38.3729\n",
      "INFO:tensorflow:loss = 693.2811, step = 101 (2.614 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.1875\n",
      "INFO:tensorflow:loss = 629.96216, step = 201 (2.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.1636\n",
      "INFO:tensorflow:loss = 653.8328, step = 301 (2.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.7042\n",
      "INFO:tensorflow:loss = 586.77405, step = 401 (2.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.1635\n",
      "INFO:tensorflow:loss = 588.95703, step = 501 (2.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.0742\n",
      "INFO:tensorflow:loss = 616.54926, step = 601 (2.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.3079\n",
      "INFO:tensorflow:loss = 626.006, step = 701 (2.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.2485\n",
      "INFO:tensorflow:loss = 626.5515, step = 801 (2.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.784\n",
      "INFO:tensorflow:loss = 672.00806, step = 901 (2.283 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into babyweight_trained/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 605.5354.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-18-12:23:07\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from babyweight_trained/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-18-12:23:08\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 1.187736, global_step = 1000, loss = 594.59894\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO:tensorflow:'serving_default' : Regression input must be a single string Tensor; got {'plurality': <tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=string>, 'gestation_weeks': <tf.Tensor 'Placeholder_3:0' shape=(?,) dtype=float32>, 'mother_age': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>, 'is_male': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=string>}\n",
      "INFO:tensorflow:'regression' : Regression input must be a single string Tensor; got {'plurality': <tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=string>, 'gestation_weeks': <tf.Tensor 'Placeholder_3:0' shape=(?,) dtype=float32>, 'mother_age': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>, 'is_male': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=string>}\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:Restoring parameters from babyweight_trained/model.ckpt-1000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b\"babyweight_trained/export/exporter/temp-b'1560860589'/saved_model.pb\"\n"
     ]
    }
   ],
   "source": [
    "# Run the model\n",
    "shutil.rmtree('babyweight_trained', ignore_errors = True) # start fresh each time\n",
    "tf.summary.FileWriterCache.clear() # ensure filewriter cache is clear for TensorBoard events file\n",
    "train_and_evaluate('babyweight_trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>TensorBoard was started successfully with pid 4052. Click <a href=\"/_proxy/58787/\" target=\"_blank\">here</a> to access it.</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4052"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.datalab.ml import TensorBoard\n",
    "TensorBoard().start('./babyweight_trained')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorBoard로 확인한 모델 구조는 다음과 같다.\n",
    "![wide-and-deep](wide_and_deep.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped TensorBoard with pid 4033\n"
     ]
    }
   ],
   "source": [
    "for pid in TensorBoard.list()['pid']:\n",
    "    TensorBoard().stop(pid)\n",
    "    print('Stopped TensorBoard with pid {}'.format(pid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2017-2018 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
